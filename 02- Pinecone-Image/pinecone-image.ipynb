{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Image Search with Pinecone and ConvBae for Feature Extraction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pinecone\n",
    "import timm    ## PyTorch Image Models (timm)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dotenv file\n",
    "_ = load_dotenv(override=True)\n",
    "pinecone_key = os.getenv('PINECONE_API_KEY')\n",
    "pinecone_env = os.getenv('PINECONE_ENV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset-images\\0009fc27d9.jpg</td>\n",
       "      <td>3054</td>\n",
       "      <td>class-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset-images\\0014c2d720.jpg</td>\n",
       "      <td>3055</td>\n",
       "      <td>class-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset-images\\00196e8fac.jpg</td>\n",
       "      <td>3056</td>\n",
       "      <td>class-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset-images\\001fc748e6.jpg</td>\n",
       "      <td>3057</td>\n",
       "      <td>class-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset-images\\002bb8e03b.jpg</td>\n",
       "      <td>3058</td>\n",
       "      <td>class-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>dataset-images\\16af889d9d.jpg</td>\n",
       "      <td>3549</td>\n",
       "      <td>class-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>dataset-images\\16b44ef03b.jpg</td>\n",
       "      <td>3550</td>\n",
       "      <td>class-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>dataset-images\\16b501e949.jpg</td>\n",
       "      <td>3551</td>\n",
       "      <td>class-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>dataset-images\\16bbc4b4dc.jpg</td>\n",
       "      <td>3552</td>\n",
       "      <td>class-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>dataset-images\\16c040e85f.jpg</td>\n",
       "      <td>3553</td>\n",
       "      <td>class-b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             paths    id    class\n",
       "0    dataset-images\\0009fc27d9.jpg  3054  class-a\n",
       "1    dataset-images\\0014c2d720.jpg  3055  class-b\n",
       "2    dataset-images\\00196e8fac.jpg  3056  class-a\n",
       "3    dataset-images\\001fc748e6.jpg  3057  class-b\n",
       "4    dataset-images\\002bb8e03b.jpg  3058  class-a\n",
       "..                             ...   ...      ...\n",
       "495  dataset-images\\16af889d9d.jpg  3549  class-b\n",
       "496  dataset-images\\16b44ef03b.jpg  3550  class-a\n",
       "497  dataset-images\\16b501e949.jpg  3551  class-b\n",
       "498  dataset-images\\16bbc4b4dc.jpg  3552  class-a\n",
       "499  dataset-images\\16c040e85f.jpg  3553  class-b\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the images paths\n",
    "imgaes_paths = [os.path.join('dataset-images', img) for img in os.listdir('dataset-images')]\n",
    "\n",
    "## Create a DF contains the images_paths and create a random ID\n",
    "df = pd.DataFrame({'paths': imgaes_paths})\n",
    "df['id'] = np.arange(3054, 3054+len(df), 1)\n",
    "\n",
    "## Take only the first 500 images --> for simplicity\n",
    "df_use = df.iloc[:500]\n",
    "df_use.loc[:, 'class'] = ['class-a', 'class-b'] * 250\n",
    "\n",
    "df_use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `ConvBase for Feature Extraction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, I will use VGG19 Model ConvBase using timm library as a convbase for feature extraction\n",
    "## The VGG19 Model after flattening the vector it will be of lenght 4096.\n",
    "\n",
    "model = timm.create_model('vgg19', pretrained=True)\n",
    "model = nn.Sequential(*list(model.children())[:-1])\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Lenght using VGG19 Model is: 4096\n"
     ]
    }
   ],
   "source": [
    "def extract_images_features(images_paths: list):\n",
    "    ''' This Function is taking a list of images_paths and returns the features extraction from them using VGG19 Model.\n",
    "    '''\n",
    "\n",
    "    ## Transformation before extraction\n",
    "    transform = transforms.Compose([   \n",
    "                            ## VGG required images (224, 224)\n",
    "                            transforms.Resize((224, 224)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                   ])\n",
    "    \n",
    "    # Looping over the images_paths\n",
    "    batch_features = []\n",
    "    for image_path in images_paths:\n",
    "        ## Convert it to Pillow and then to tensor\n",
    "        image_tensor = Image.open(image_path).convert('RGB')\n",
    "        image_tensor = transform(image_tensor).unsqueeze(0)\n",
    "\n",
    "        ## Pass the Image and get the Feature Extraction\n",
    "        with torch.no_grad():\n",
    "            conv_features = model(image_tensor)\n",
    "            ## Flatten --> I want a vector as a list in 1D\n",
    "            image_features = conv_features.view(conv_features.size(0), -1).tolist()[0]\n",
    "\n",
    "        ## Append to the list\n",
    "        batch_features.append(image_features)\n",
    "\n",
    "    return batch_features\n",
    "\n",
    "## Test the above function\n",
    "vgg19_vect_length = len(extract_images_features(images_paths=[r'dataset-images\\0009fc27d9.jpg'])[0])\n",
    "print(f'Vector Lenght using VGG19 Model is: {vgg19_vect_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Upserting to Pinecone`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting existing indexes for free tier ..\n",
      "Creating New Index: image-vgg19model-course ...\n",
      "Done ...\n"
     ]
    }
   ],
   "source": [
    "## Connect to pinecone\n",
    "pinecone.init(\n",
    "        api_key=pinecone_key,\n",
    "        environment=pinecone_env\n",
    "            )\n",
    "\n",
    "## For Free tier, Only one index is accepted --> So removing any other indexes firstly\n",
    "try:\n",
    "    print('Deleting existing indexes for free tier ..')\n",
    "    _ = [pinecone.delete_index(name=name) for name in pinecone.list_indexes()]\n",
    "except:\n",
    "    print('No existing indexes ..')\n",
    "\n",
    "## Create the index\n",
    "index_name = 'image-vgg19model-course'\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    print(f'Creating New Index: {index_name} ...')  \n",
    "    ## Create\n",
    "    pinecone.create_index(name=index_name, dimension=vgg19_vect_length, metric='cosine') ## and more like (pods=1, pod_type='p1.x1')\n",
    "    print('Done ...')\n",
    "\n",
    "## Index Now is Created, But we want to connect it to upsert vectors to it\n",
    "index = pinecone.Index(index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [05:17<00:00, 19.87s/it]\n"
     ]
    }
   ],
   "source": [
    "## Create a Function for Upserting to Pinecone\n",
    "def upsert_to_pinecone(df_images, batch_size=32):\n",
    "\n",
    "    failed_ids = []\n",
    "\n",
    "    for batch_start in tqdm(range(0, len(df_images), batch_size)):\n",
    "        try:\n",
    "            ## Prepare Batches\n",
    "            batch_end = min(batch_start+batch_size, len(df_images))\n",
    "            paths_batch = df_images['paths'][batch_start: batch_end].tolist()         ## Slice the DF according to each batch\n",
    "            ids_batch = df_images['id'][batch_start: batch_end].astype(str).tolist()  ## Also, Slice for the Ids according to each batch\n",
    "            metadata_batch = df_images['class'][batch_start: batch_end].tolist()      ## The metadata to be used in filtering\n",
    "\n",
    "            ## Call the function (extract_images_features) for getting features for each batch\n",
    "            batch_features = extract_images_features(images_paths=paths_batch)\n",
    "\n",
    "            ## Prepare to pinecone \n",
    "            # to_upsert = list(zip(ids_batch, batch_features))\n",
    "            to_upsert = [(id, feats, {'class': cls}) for id, feats, cls in zip(ids_batch, batch_features, metadata_batch)]\n",
    "\n",
    "            ## Insert to pinecone\n",
    "            _ = index.upsert(vectors=to_upsert, namespace='image-vgg19')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error Upserting: {e}')\n",
    "            failed_ids.append(ids_batch)\n",
    "    \n",
    "    return failed_ids\n",
    "\n",
    "\n",
    "## Apply the Function\n",
    "failed_ids = upsert_to_pinecone(df_images=df_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '3263',\n",
       "  'metadata': {'class': 'class-b'},\n",
       "  'score': 0.706210434,\n",
       "  'values': []},\n",
       " {'id': '3439',\n",
       "  'metadata': {'class': 'class-b'},\n",
       "  'score': 0.553301871,\n",
       "  'values': []},\n",
       " {'id': '3491',\n",
       "  'metadata': {'class': 'class-b'},\n",
       "  'score': 0.496369809,\n",
       "  'values': []},\n",
       " {'id': '3167',\n",
       "  'metadata': {'class': 'class-b'},\n",
       "  'score': 0.466286302,\n",
       "  'values': []},\n",
       " {'id': '3527',\n",
       "  'metadata': {'class': 'class-b'},\n",
       "  'score': 0.410927862,\n",
       "  'values': []}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get simialrity in real-time\n",
    "image_new_path = df['paths'].iloc[-1]\n",
    "image_feats_new = extract_images_features(images_paths=[image_new_path])[0]\n",
    "\n",
    "## Search the Vector Store\n",
    "results = index.query(queries=[image_feats_new], top_k=5, include_metadata=True, filter={'class': 'class-b'}, namespace='image-vgg19')\n",
    "results['results'][0]['matches']\n",
    "# [record['id'] for record in results['matches']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can delete vectors using ids\n",
    "_ = index.delete(ids=['3328', '3152'], namespace='image-vgg19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First 10 values of the above vector is : \n",
      " [0.0, 1.3136866092681885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "## To update the embeddings of any id \n",
    "image_path_update = df['paths'].iloc[-1]\n",
    "image_feats_update = extract_images_features(images_paths=[image_path_update])[0]\n",
    "print(f'The First 10 values of the above vector is : \\n {image_feats_update[:10]}')\n",
    "\n",
    "## Update or you can use upsert (with different image --> Pinecone will upadate the vector)\n",
    "_ = index.update(id='3096', values=image_feats_update, namespace='image-vgg19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.31368661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## You can Fetch Vectors using ids\n",
    "index.fetch(ids=['3096'], namespace='image-vgg19')['vectors']['3096']['values'][:10] ## Compare it with above values (Great, It is already updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', [3, 4, 5], {'class': 'a'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(['5', [3, 4, 5], {'class': 'a'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5', [3, 4, 5], {'class': 'a'})]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[('5', [3, 4, 5], {'class': 'a'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
