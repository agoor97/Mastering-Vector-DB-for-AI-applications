{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Image Search with Pinecone and ConvBae for Feature Extraction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\anaconda3\\envs\\vectdb\\lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "## Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pinecone\n",
    "import timm    ## PyTorch Image Models (timm)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dotenv file\n",
    "_ = load_dotenv(override=True)\n",
    "pinecone_key = os.getenv('PINECONE_API_KEY')\n",
    "pinecone_env = os.getenv('PINECONE_ENV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets\\dataset-images\\0009fc27d9.jpg</td>\n",
       "      <td>3054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets\\dataset-images\\0014c2d720.jpg</td>\n",
       "      <td>3055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets\\dataset-images\\00196e8fac.jpg</td>\n",
       "      <td>3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets\\dataset-images\\001fc748e6.jpg</td>\n",
       "      <td>3057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets\\dataset-images\\002bb8e03b.jpg</td>\n",
       "      <td>3058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>datasets\\dataset-images\\16af889d9d.jpg</td>\n",
       "      <td>3549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>datasets\\dataset-images\\16b44ef03b.jpg</td>\n",
       "      <td>3550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>datasets\\dataset-images\\16b501e949.jpg</td>\n",
       "      <td>3551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>datasets\\dataset-images\\16bbc4b4dc.jpg</td>\n",
       "      <td>3552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>datasets\\dataset-images\\16c040e85f.jpg</td>\n",
       "      <td>3553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      paths    id\n",
       "0    datasets\\dataset-images\\0009fc27d9.jpg  3054\n",
       "1    datasets\\dataset-images\\0014c2d720.jpg  3055\n",
       "2    datasets\\dataset-images\\00196e8fac.jpg  3056\n",
       "3    datasets\\dataset-images\\001fc748e6.jpg  3057\n",
       "4    datasets\\dataset-images\\002bb8e03b.jpg  3058\n",
       "..                                      ...   ...\n",
       "495  datasets\\dataset-images\\16af889d9d.jpg  3549\n",
       "496  datasets\\dataset-images\\16b44ef03b.jpg  3550\n",
       "497  datasets\\dataset-images\\16b501e949.jpg  3551\n",
       "498  datasets\\dataset-images\\16bbc4b4dc.jpg  3552\n",
       "499  datasets\\dataset-images\\16c040e85f.jpg  3553\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the images paths\n",
    "FOLDER_PATH = os.path.join('datasets', 'dataset-images')\n",
    "iamges_paths = [os.path.join(FOLDER_PATH, img) for img in os.listdir(FOLDER_PATH)]\n",
    "\n",
    "## Create a DF contains the images_paths and create a random ID\n",
    "df = pd.DataFrame({'paths': iamges_paths})\n",
    "df['id'] = np.arange(3054, 3054+len(df), 1)\n",
    "\n",
    "## Take only the first 500 images --> for simplicity\n",
    "df_use = df.iloc[:500]\n",
    "df_use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `ConvBase for Feature Extraction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, I will use VGG19 Model ConvBase using timm library as a convbase for feature extraction\n",
    "## The VGG19 Model after flattening the vector it will be of lenght 4096.\n",
    "\n",
    "model = timm.create_model('vgg19', pretrained=True)\n",
    "model = nn.Sequential(*list(model.children())[:-1])\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Lenght using VGG19 Model is: 4096\n"
     ]
    }
   ],
   "source": [
    "def extract_images_features(images_paths: list):\n",
    "    ''' This Function is taking a list of images_paths and returns the features extraction from them using VGG19 Model.\n",
    "    '''\n",
    "\n",
    "    ## Transformation before extraction\n",
    "    transform = transforms.Compose([   \n",
    "                            ## VGG required images (224, 224)\n",
    "                            transforms.Resize((224, 224)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                   ])\n",
    "    \n",
    "    # Looping over the images_paths\n",
    "    batch_features = []\n",
    "    for image_path in images_paths:\n",
    "        ## Convert it to Pillow and then to tensor\n",
    "        image_tensor = Image.open(image_path).convert('RGB')\n",
    "        image_tensor = transform(image_tensor).unsqueeze(0)\n",
    "\n",
    "        ## Pass the Image and get the Feature Extraction\n",
    "        with torch.no_grad():\n",
    "            conv_features = model(image_tensor)\n",
    "            ## Flatten --> I want a vector as a list in 1D\n",
    "            image_features = conv_features.view(conv_features.size(0), -1).tolist()[0]\n",
    "\n",
    "        ## Append to the list\n",
    "        batch_features.append(image_features)\n",
    "\n",
    "    return batch_features\n",
    "\n",
    "## Test the above function\n",
    "vgg19_vect_length = len(extract_images_features(images_paths=[r'datasets\\dataset-images\\0009fc27d9.jpg'])[0])\n",
    "print(f'Vector Lenght using VGG19 Model is: {vgg19_vect_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Upserting to Pinecone`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting existing indexes for free tier ..\n",
      "Creating New Index: image-vgg19-course ...\n",
      "Done ...\n"
     ]
    }
   ],
   "source": [
    "## Connect to pinecone\n",
    "pinecone.init(\n",
    "        api_key=pinecone_key,\n",
    "        environment=pinecone_env\n",
    "            )\n",
    "\n",
    "## For Free tier, Only one index is accepted --> So removing any other indexes firstly\n",
    "try:\n",
    "    print('Deleting existing indexes for free tier ..')\n",
    "    _ = [pinecone.delete_index(name=name) for name in pinecone.list_indexes()]\n",
    "except:\n",
    "    print('No existing indexes ..')\n",
    "\n",
    "## Create the index\n",
    "index_name = 'image-vgg19-course'\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    print(f'Creating New Index: {index_name} ...')  \n",
    "    ## Create\n",
    "    pinecone.create_index(name=index_name, dimension=vgg19_vect_length, metric='cosine') ## and more like (pods=1, pod_type='p1.x1')\n",
    "    print('Done ...')\n",
    "\n",
    "## Index Now is Created, But we want to connect it to upsert vectors to it\n",
    "index = pinecone.Index(index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [06:04<00:00, 22.79s/it]\n"
     ]
    }
   ],
   "source": [
    "## Create a Function for Upserting to Pinecone\n",
    "def upsert_to_pinecone(df_images, batch_size=32):\n",
    "\n",
    "    failed_ids = []\n",
    "\n",
    "    for batch_start in tqdm(range(0, len(df_images), batch_size)):\n",
    "        try:\n",
    "            ## Prepare Batches\n",
    "            batch_end = min(batch_start+batch_size, len(df_images))\n",
    "            paths_batch = df_images['paths'][batch_start: batch_end].tolist()    ## Slice the DF according to each batch\n",
    "            ids_batch = df_images['id'][batch_start: batch_end].tolist()         ## Also, Slice for the Ids according to each batch\n",
    "            ids_batch_str = [str(id) for id in ids_batch]                        ## Prefered to be string\n",
    "\n",
    "            ## Call the function (extract_images_features) for getting features for each batch\n",
    "            batch_features = extract_images_features(images_paths=paths_batch)\n",
    "\n",
    "            ## Prepare to pinecone \n",
    "            to_upsert = list(zip(ids_batch_str, batch_features))\n",
    "\n",
    "            ## Insert to pinecone\n",
    "            _ = index.upsert(vectors=to_upsert)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error Upserting: {e}')\n",
    "            failed_ids.append(ids_batch)\n",
    "    \n",
    "    return failed_ids\n",
    "\n",
    "\n",
    "## Apply the Function\n",
    "failed_ids = upsert_to_pinecone(df_images=df_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '3263', 'score': 0.706210434, 'values': []},\n",
       " {'id': '3439', 'score': 0.553301871, 'values': []},\n",
       " {'id': '3080', 'score': 0.499896258, 'values': []},\n",
       " {'id': '3491', 'score': 0.496369809, 'values': []},\n",
       " {'id': '3124', 'score': 0.469109565, 'values': []},\n",
       " {'id': '3167', 'score': 0.466286302, 'values': []},\n",
       " {'id': '3204', 'score': 0.419103652, 'values': []},\n",
       " {'id': '3527', 'score': 0.410927862, 'values': []},\n",
       " {'id': '3177', 'score': 0.40235883, 'values': []},\n",
       " {'id': '3364', 'score': 0.3941544, 'values': []},\n",
       " {'id': '3524', 'score': 0.379548311, 'values': []},\n",
       " {'id': '3135', 'score': 0.367767125, 'values': []},\n",
       " {'id': '3310', 'score': 0.362493187, 'values': []},\n",
       " {'id': '3381', 'score': 0.358663797, 'values': []},\n",
       " {'id': '3096', 'score': 0.34970957, 'values': []}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get simialrity in real-time\n",
    "image_new_path = df['paths'].iloc[-1]\n",
    "image_feats_new = extract_images_features(images_paths=[image_new_path])[0]\n",
    "\n",
    "## Search the Vector Store\n",
    "results = index.query(vector=image_feats_new, top_k=15)\n",
    "results['matches']\n",
    "# [record['id'] for record in results['matches']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can delete vectors using ids\n",
    "_ = index.delete(ids=['3328', '3152'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First 10 values of the above vector is : \n",
      " [0.0, 1.3136866092681885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "## To update the embeddings of any id \n",
    "image_path_update = df['paths'].iloc[-1]\n",
    "image_feats_update = extract_images_features(images_paths=[image_path_update])[0]\n",
    "print(f'The First 10 values of the above vector is : \\n {image_feats_update[:10]}')\n",
    "\n",
    "## Update or you can use upsert (with different image --> Pinecone will upadate the vector)\n",
    "_ = index.update(id='3096', values=image_feats_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.31368661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## You can Fetch Vectors using ids\n",
    "index.fetch(ids=['3096'])['vectors']['3096']['values'][:10] ## Compare it with above values (Great, It is already updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
